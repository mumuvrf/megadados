{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e37c0df-e67b-449d-8048-3be19047ab6d",
   "metadata": {},
   "source": [
    "# Exercicios com Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "562f41a9-c638-4e0f-9493-77654a650474",
   "metadata": {},
   "source": [
    "Caso precise, abaixo estão os comandos para iniciar o container:\n",
    "\n",
    "Para macOS e linux, utilize:\n",
    "\n",
    "```bash\n",
    "docker run \\\n",
    "    -it \\\n",
    "    --rm \\\n",
    "    -p 8888:8888 \\\n",
    "    -p 4040:4040 \\\n",
    "    -v \"`pwd`\":/home/jovyan/work \\\n",
    "    jupyter/pyspark-notebook\n",
    "\n",
    "\n",
    "```\n",
    "\n",
    "Se estiver no Windows estes comandos, utilize:\n",
    "\n",
    "- No Powershell: `docker run -it --rm -p 8888:8888 -p 4040:4040 -v ${PWD}:/home/jovyan/work jupyter/pyspark-notebook`\n",
    "\n",
    "- No Prompt de comando: `docker run -it --rm -p 8888:8888 -p 4040:4040 -v %cd%:/home/jovyan/work jupyter/pyspark-notebook`\n",
    "\n",
    "Agora abra esse notebook lá no container!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b7292d9-4aa8-47c3-938b-3922cd4be036",
   "metadata": {},
   "source": [
    "## Iniciando o Spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69c208f2-a1ef-4f30-bf7c-5ed01e20246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "\n",
    "conf = pyspark.SparkConf()\n",
    "conf.setAppName(\"Minha aplicação\")\n",
    "conf.setMaster(\"local[*]\")\n",
    "\n",
    "sc = pyspark.SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b95e478c-cfe7-4bca-8ebf-6c34dd38aeeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://e70bd02c9d7e:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.5.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Minha aplicação</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        "
      ],
      "text/plain": [
       "<SparkContext master=local[*] appName=Minha aplicação>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "765d74df",
   "metadata": {},
   "source": [
    "## Iniciando a biblioteca de correção"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e76b5478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install git+https://github.com/macielcalebe/insperautograding.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b3f05694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import insperautograder.jupyter as ia\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e29fe40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|    | Atividade            | De                  | Até                 | Conta como ATV?   | % Nota Atraso   |\n",
       "|---:|:---------------------|:--------------------|:--------------------|:------------------|:----------------|\n",
       "|  0 | newborn              | 2025-02-01 00:00:00 | 2025-05-30 00:00:00 | Não               | 0%              |\n",
       "|  1 | select01             | 2025-02-05 00:00:00 | 2025-02-15 23:59:59 | Sim               | 25%             |\n",
       "|  2 | ddl                  | 2025-02-19 00:00:00 | 2025-02-26 23:59:59 | Sim               | 25%             |\n",
       "|  3 | dml                  | 2025-02-24 00:00:00 | 2025-03-09 23:59:59 | Sim               | 25%             |\n",
       "|  4 | agg_join             | 2025-02-26 00:00:00 | 2025-03-09 23:59:59 | Sim               | 25%             |\n",
       "|  5 | group_having         | 2025-03-10 00:00:00 | 2025-03-17 23:59:59 | Sim               | 25%             |\n",
       "|  6 | views                | 2025-03-12 00:00:00 | 2025-03-19 23:59:59 | Sim               | 25%             |\n",
       "|  7 | sql_review1          | 2025-03-17 00:00:00 | 2025-03-23 23:59:59 | Sim               | 25%             |\n",
       "|  8 | ai_md_23_2           | 2025-03-23 00:00:00 | 2025-03-30 23:59:59 | Sim               | 25%             |\n",
       "|  9 | ai_md_23_1           | 2025-03-23 00:00:00 | 2025-03-30 23:59:59 | Sim               | 25%             |\n",
       "| 10 | permissions          | 2025-03-24 00:00:00 | 2025-04-08 23:59:59 | Sim               | 25%             |\n",
       "| 11 | ai_md_25_1           | 2025-03-31 00:00:00 | 2025-03-31 10:05:00 | Não               | 0%              |\n",
       "| 12 | desafio_normalizacao | 2025-04-07 00:00:00 | 2025-05-30 00:00:00 | Não               | 0%              |\n",
       "| 13 | triggers             | 2025-04-23 00:00:00 | 2025-05-04 23:59:59 | Sim               | 25%             |\n",
       "| 14 | functional           | 2025-05-05 00:00:00 | 2025-05-11 23:59:59 | Sim               | 25%             |\n",
       "| 15 | spark                | 2025-05-07 00:00:00 | 2025-05-14 23:59:59 | Sim               | 25%             |\n",
       "| 16 | exercicios_spark     | 2025-05-12 00:00:00 | 2025-05-18 23:59:59 | Sim               | 25%             |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ia.tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2d6f05ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|    | Atividade        | Exercício   |   Peso |   Nota |   Nota Sem Atraso |   Nota Com Atraso |\n",
       "|---:|:-----------------|:------------|-------:|-------:|------------------:|------------------:|\n",
       "|  0 | exercicios_spark | ex01        |      1 |     10 |                10 |                 0 |\n",
       "|  1 | exercicios_spark | ex02        |      1 |     10 |                10 |                 0 |\n",
       "|  2 | exercicios_spark | ex03        |      1 |     10 |                10 |                 0 |\n",
       "|  3 | exercicios_spark | ex04        |      1 |     10 |                10 |                 0 |\n",
       "|  4 | exercicios_spark | ex05        |      1 |      0 |                 0 |                 0 |\n",
       "|  5 | exercicios_spark | ex06        |      1 |      0 |                 0 |                 0 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ia.grades(task=\"exercicios_spark\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3099ef4-2117-47a8-8a1d-af2df7814056",
   "metadata": {},
   "source": [
    "## Trabalhando com Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "483b1de3-9e55-46ce-99e8-526b05b8c3d2",
   "metadata": {},
   "source": [
    "Para este exercicio vamos trabalhar com o dataset de reviews da Amazon visto em https://www.kaggle.com/datasets/kritanjalijain/amazon-reviews.\n",
    "\n",
    "Baixe o arquivo \"train.csv\" direto do Kaggle, ou pelo link https://bigdata-22-2.s3.us-east-2.amazonaws.com/amazon_sentiment/train.csv.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65caf38e-fbd8-4513-af02-37671c6a949b",
   "metadata": {},
   "source": [
    "Vamos ler o arquivo \"train.csv\" em um RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e64ec721-3b7f-46b8-a8a9-d27ccc83f209",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd = sc.textFile(\"train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5b73e675-ea3b-49c2-8622-53e8c17cfdf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"2\",\"Stuning even for the non-gamer\",\"This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^\"']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4794fc0-59cf-497f-98fc-d20efc0cca2b",
   "metadata": {},
   "source": [
    "De acordo com a documentação deste arquivo vista no Kaggle, cada linha contem 2 elementos: o sentimento do review (1 - negativo, 2 - positivo), o título e o corpo do review. A linha contem esses elementos em um formato \"comma-separated value\" (CSV), onde cada um dos campos está delimitado por aspas duplas. Se o texto em si (titulo ou corpo) contem aspas, elas aparecem como um par de aspas duplas. Vamos usar o `.filter()` para achar um exemplo desses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef3c736d-0378-43f7-be05-3e7f53b1423e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"2\",\"Amazing!\",\"This soundtrack is my favorite music of all time, hands down. The intense sadness of \"\"Prisoners of Fate\"\" (which means all the more if you\\'ve played the game) and the hope in \"\"A Distant Promise\"\" and \"\"Girl who Stole the Star\"\" have been an important inspiration to me personally throughout my teen years. The higher energy tracks like \"\"Chrono Cross ~ Time\\'s Scar~\"\", \"\"Time of the Dreamwatch\"\", and \"\"Chronomantique\"\" (indefinably remeniscent of Chrono Trigger) are all absolutely superb as well.This soundtrack is amazing music, probably the best of this composer\\'s work (I haven\\'t heard the Xenogears soundtrack, so I can\\'t say for sure), and even if you\\'ve never played the game, it would be worth twice the price to buy it.I wish I could give it 6 stars.\"'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_line = rdd.filter(lambda x: '\"\"' in x).take(1)\n",
    "example_line = example_line[0]\n",
    "\n",
    "example_line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efc0e86d-122f-4c0e-bf36-a0a8e2f60559",
   "metadata": {},
   "source": [
    "Levando isso em consideração, vamos fazer uma função simples para separar os campos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4923aa8b-1bee-4c74-8d18-6f4cf0445b0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_line(line):\n",
    "    parts = line[1:-1].split('\",\"')\n",
    "    sentiment = int(parts[0])\n",
    "    title = parts[1].replace('\"\"', '\"')\n",
    "    body = parts[2].replace('\"\"', '\"')\n",
    "    return (sentiment, title, body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "82f380c6-469c-4dd2-baa5-cbe72110de7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " 'Amazing!',\n",
       " 'This soundtrack is my favorite music of all time, hands down. The intense sadness of \"Prisoners of Fate\" (which means all the more if you\\'ve played the game) and the hope in \"A Distant Promise\" and \"Girl who Stole the Star\" have been an important inspiration to me personally throughout my teen years. The higher energy tracks like \"Chrono Cross ~ Time\\'s Scar~\", \"Time of the Dreamwatch\", and \"Chronomantique\" (indefinably remeniscent of Chrono Trigger) are all absolutely superb as well.This soundtrack is amazing music, probably the best of this composer\\'s work (I haven\\'t heard the Xenogears soundtrack, so I can\\'t say for sure), and even if you\\'ve never played the game, it would be worth twice the price to buy it.I wish I could give it 6 stars.')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parse_line(example_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad8249e3-6f4a-4ed0-81b5-a453d141b88b",
   "metadata": {},
   "source": [
    "Podemos agora utilizar nossa função para separar os campos de cada linha do dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "59d103d0-ae4d-4912-ba1b-8133f12d4e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "rdd_split = rdd.map(parse_line)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a64fbea0-1378-4be7-b1d7-ada7828735b4",
   "metadata": {},
   "source": [
    "Como de costume, nada realmente acontece até que uma \"action\" seja invocada. O `.map()` é uma \"transformation\". Vamos usar uma action simples para \"materializar\" o novo RDD."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "06b670e5-1757-443b-a229-453e3e3115b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3600000"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_split.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ff144ad-9378-4b72-ae84-1b1d2dda815d",
   "metadata": {},
   "source": [
    "Vamos explorar os resultados para ver se deu certo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd7882d9-4502-406b-abc4-b74de6fa1aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(2,\n",
       "  'Stuning even for the non-gamer',\n",
       "  'This sound track was beautiful! It paints the senery in your mind so well I would recomend it even to people who hate vid. game music! I have played the game Chrono Cross but out of all of the games I have ever played it has the best music! It backs away from crude keyboarding and takes a fresher step with grate guitars and soulful orchestras. It would impress anyone who cares to listen! ^_^')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_split.take(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3317a957-f13d-49fe-b193-9c6826616cc7",
   "metadata": {},
   "source": [
    "**Atividade**: Implemente uma função que recebe o rdd processado e conte quantos sentimentos diferentes existem, e quantas vezes aparecem, para confirmar que só tem os sentimentos 1 e 2. Sua função deve retornar o resultado em tuplas, onde o primeiro elemento é o sentimento e o segundo é a contagem de vezes que aparece."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cf4ed566",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 1800000), (2, 1800000)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ex01(rdd_split):\n",
    "    rdd_sentiment = rdd_split.map(lambda x: (x[0], 1))\\\n",
    "                            .reduceByKey(lambda x, y: x+y)\n",
    "    return rdd_sentiment.collect() # Pode alterar o retorno, se necessário!\n",
    "    \n",
    "ex01(rdd_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e0248377",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55c796787e8b47ebbc251fcef8b652e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Button(description='Enviar ex01', style=ButtonStyle()), Output()), _dom_classes=('widget…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ia.sender(answer=\"ex01\", task=\"exercicios_spark\", question=\"ex01\", answer_type=\"pycode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fffe0feb-e926-485d-80c0-897bf7820e47",
   "metadata": {},
   "source": [
    "**Atividade**: Implemente uma função que recebe o rdd processado e retorna quantos reviews não tem titulo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "674cdb01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ex02(rdd_split):\n",
    "    rdd_no_title = rdd_split.filter(lambda x: x[1] == '').count()\n",
    "    return rdd_no_title # Pode alterar o retorno, se necessário!\n",
    "\n",
    "ex02(rdd_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e3aa482a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d58d3bfa22324fd0b350d9eef893c8eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Button(description='Enviar ex02', style=ButtonStyle()), Output()), _dom_classes=('widget…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ia.sender(answer=\"ex02\", task=\"exercicios_spark\", question=\"ex02\", answer_type=\"pycode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a31da43c-d2a5-4806-a5bf-9765e7fb09f9",
   "metadata": {},
   "source": [
    "**Atividade**: Implemente uma função que recebe o rdd processado e retorna quantos reviews não tem corpo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6ae32e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ex03(rdd_split):\n",
    "    rdd_no_body = rdd_split.filter(lambda x: x[2] == '').count()\n",
    "    return rdd_no_body # Pode alterar o retorno, se necessário!\n",
    "\n",
    "ex03(rdd_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84bf1280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "27b0184af73e4e3f86bd675e6b249f6a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Button(description='Enviar ex03', style=ButtonStyle()), Output()), _dom_classes=('widget…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ia.sender(answer=\"ex03\", task=\"exercicios_spark\", question=\"ex03\", answer_type=\"pycode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76d3fd0-af72-4b2e-aa61-7ffc897b86c1",
   "metadata": {},
   "source": [
    "**Atividade**: Implemente uma função que recebe o rdd processado e retorna qual o comprimento máximo de um título e de um corpo. O resultado deve ser uma tupla com os dois valores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4f286058",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(139, 1010)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ex04(rdd_split):\n",
    "    max_title_size = rdd_split.map(lambda x: len(x[1]))\\\n",
    "                            .takeOrdered(1, lambda x: -x)[0]\n",
    "\n",
    "    max_body_size = rdd_split.map(lambda x: len(x[2]))\\\n",
    "                            .takeOrdered(1, lambda x: -x)[0]\n",
    "    \n",
    "    return (max_title_size, max_body_size) # Pode alterar o retorno, se necessário!\n",
    "    \n",
    "ex04(rdd_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e5c9e4b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8522cd468da04f379af9b94b2d24570f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Button(description='Enviar ex04', style=ButtonStyle()), Output()), _dom_classes=('widget…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ia.sender(answer=\"ex04\", task=\"exercicios_spark\", question=\"ex04\", answer_type=\"pycode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d96887-6d6d-494e-9ac0-0c06b5c08dc6",
   "metadata": {},
   "source": [
    "**Atividade**: Implemente uma função que recebe o rdd processado e retorna qual a maior palavra palíndroma sem pontuações do dataset (no titulo ou corpo) e seu tamanho.\n",
    "\n",
    "Para este exercício, está permitido o uso de list comprehensions.\n",
    "\n",
    "**Obs**: Após o split, se uma palavra tiver alguma `string.punctuation`, ela deve ser desconsiderada (ao invés de remover as pontuações da palavra, remova as palavras com alguma pontuação)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ff6df655",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c1755cfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('lllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll', 63)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ex05(rdd_split):\n",
    "    def ha_pontuacao(palavra):\n",
    "        for char in palavra:\n",
    "            if char in string.punctuation:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    palavras = rdd_split.map(lambda x: x[1] + ' ' + x[2])\n",
    "\n",
    "    palindromos = palavras.flatMap(lambda x: x.split())\\\n",
    "                        .filter(lambda x: x == x[::-1])\\\n",
    "                        .filter(ha_pontuacao)\n",
    "\n",
    "    maior_palindromo = palindromos.takeOrdered(1, lambda x: -len(x))[0]\n",
    "    \n",
    "    return (maior_palindromo, len(maior_palindromo)) # Pode alterar o retorno, se necessário!\n",
    "\n",
    "ex05(rdd_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7aa180dd-b4ca-4db5-a2fd-c3c33818abec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "446ef93ab20c4536a68e29c230082a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Button(description='Enviar ex05', style=ButtonStyle()), Output()), _dom_classes=('widget…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ia.sender(answer=\"ex05\", task=\"exercicios_spark\", question=\"ex05\", answer_type=\"pycode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d63f641d-1d98-4d84-8f7b-93b122ae057c",
   "metadata": {},
   "source": [
    "**Atividade**: Implemente uma função que recebe o rdd processado e retorna as 20 palavras mais populares do titulo com sua frequência absoluta. Teste no subconjunto apresentado abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6faf3c82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 348807),\n",
       " ('a', 249841),\n",
       " ('of', 241846),\n",
       " ('for', 220429),\n",
       " ('and', 190973),\n",
       " ('to', 177502),\n",
       " ('A', 173889),\n",
       " ('Great', 168288),\n",
       " ('I', 145120),\n",
       " ('is', 143982),\n",
       " ('Not', 140413),\n",
       " ('not', 128331),\n",
       " ('this', 121247),\n",
       " ('The', 119549),\n",
       " ('it', 107117),\n",
       " ('but', 95869),\n",
       " ('book', 95629),\n",
       " ('good', 87873),\n",
       " ('Good', 86357),\n",
       " ('in', 84964)]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def ex06(rdd_split):\n",
    "    mais_populares = rdd_split.flatMap(lambda x: x[1].split())\\\n",
    "                            .map(lambda x: (x, 1))\\\n",
    "                            .reduceByKey(lambda x, y: x+y)\\\n",
    "                            .takeOrdered(20, lambda x: -x[1])\n",
    "\n",
    "    return mais_populares # Pode alterar o retorno, se necessário!\n",
    "\n",
    "ex06(rdd_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cd2e4518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 17380),\n",
       " ('a', 12537),\n",
       " ('of', 11944),\n",
       " ('for', 11143),\n",
       " ('and', 9590),\n",
       " ('to', 8853),\n",
       " ('A', 8536),\n",
       " ('Great', 8475),\n",
       " ('is', 7305),\n",
       " ('I', 7187),\n",
       " ('Not', 6953),\n",
       " ('not', 6424),\n",
       " ('this', 5995),\n",
       " ('The', 5933),\n",
       " ('it', 5349),\n",
       " ('book', 4774),\n",
       " ('but', 4693),\n",
       " ('good', 4404),\n",
       " ('in', 4313),\n",
       " ('Good', 4295)]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdd_redux = rdd_split.sample(False, 0.05, 7)\n",
    "ex06(rdd_redux)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c1a18e2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70e207f8c41649658e8fa9663d44df89",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Button(description='Enviar ex06', style=ButtonStyle()), Output()), _dom_classes=('widget…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ia.sender(answer=\"ex06\", task=\"exercicios_spark\", question=\"ex06\", answer_type=\"pycode\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb5ee10",
   "metadata": {},
   "source": [
    "## Conferir notas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "acc0d272",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|    | Atividade            | De                  | Até                 | Conta como ATV?   | % Nota Atraso   |\n",
       "|---:|:---------------------|:--------------------|:--------------------|:------------------|:----------------|\n",
       "|  0 | newborn              | 2025-02-01 00:00:00 | 2025-05-30 00:00:00 | Não               | 0%              |\n",
       "|  1 | select01             | 2025-02-05 00:00:00 | 2025-02-15 23:59:59 | Sim               | 25%             |\n",
       "|  2 | ddl                  | 2025-02-19 00:00:00 | 2025-02-26 23:59:59 | Sim               | 25%             |\n",
       "|  3 | dml                  | 2025-02-24 00:00:00 | 2025-03-09 23:59:59 | Sim               | 25%             |\n",
       "|  4 | agg_join             | 2025-02-26 00:00:00 | 2025-03-09 23:59:59 | Sim               | 25%             |\n",
       "|  5 | group_having         | 2025-03-10 00:00:00 | 2025-03-17 23:59:59 | Sim               | 25%             |\n",
       "|  6 | views                | 2025-03-12 00:00:00 | 2025-03-19 23:59:59 | Sim               | 25%             |\n",
       "|  7 | sql_review1          | 2025-03-17 00:00:00 | 2025-03-23 23:59:59 | Sim               | 25%             |\n",
       "|  8 | ai_md_23_2           | 2025-03-23 00:00:00 | 2025-03-30 23:59:59 | Sim               | 25%             |\n",
       "|  9 | ai_md_23_1           | 2025-03-23 00:00:00 | 2025-03-30 23:59:59 | Sim               | 25%             |\n",
       "| 10 | permissions          | 2025-03-24 00:00:00 | 2025-04-08 23:59:59 | Sim               | 25%             |\n",
       "| 11 | ai_md_25_1           | 2025-03-31 00:00:00 | 2025-03-31 10:05:00 | Não               | 0%              |\n",
       "| 12 | desafio_normalizacao | 2025-04-07 00:00:00 | 2025-05-30 00:00:00 | Não               | 0%              |\n",
       "| 13 | triggers             | 2025-04-23 00:00:00 | 2025-05-04 23:59:59 | Sim               | 25%             |\n",
       "| 14 | functional           | 2025-05-05 00:00:00 | 2025-05-11 23:59:59 | Sim               | 25%             |\n",
       "| 15 | spark                | 2025-05-07 00:00:00 | 2025-05-14 23:59:59 | Sim               | 25%             |\n",
       "| 16 | exercicios_spark     | 2025-05-12 00:00:00 | 2025-05-18 23:59:59 | Sim               | 25%             |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ia.tasks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b4bb06e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "|    | Atividade        | Exercício   |   Peso |   Nota |   Nota Sem Atraso |   Nota Com Atraso |\n",
       "|---:|:-----------------|:------------|-------:|-------:|------------------:|------------------:|\n",
       "|  0 | exercicios_spark | ex01        |      1 |     10 |                10 |                 0 |\n",
       "|  1 | exercicios_spark | ex02        |      1 |     10 |                10 |                 0 |\n",
       "|  2 | exercicios_spark | ex03        |      1 |     10 |                10 |                 0 |\n",
       "|  3 | exercicios_spark | ex04        |      1 |     10 |                10 |                 0 |\n",
       "|  4 | exercicios_spark | ex05        |      1 |     10 |                10 |                 0 |\n",
       "|  5 | exercicios_spark | ex06        |      1 |     10 |                10 |                 0 |"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ia.grades(task=\"exercicios_spark\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "117d9ee0-b96e-408b-86b3-aa0321260cbe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
